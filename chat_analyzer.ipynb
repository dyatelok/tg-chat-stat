{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyatelok/tg-chat-stat/blob/main/chat_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji"
      ],
      "metadata": {
        "id": "JHMroDlnTOGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install names"
      ],
      "metadata": {
        "id": "IZDhXg4RTSmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import emoji\n",
        "import numpy\n",
        "import names\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import json\n",
        "from pandas import json_normalize"
      ],
      "metadata": {
        "id": "YSVKmX1__J4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#open text file in read mode\n",
        "text_file = open(\"wiki_logs.json\", \"r\")\n",
        "\n",
        "#read whole file to a string\n",
        "data = text_file.read()\n",
        "\n",
        "#close file\n",
        "text_file.close()\n",
        "\n",
        "dict = json.loads(data)\n",
        "df = json_normalize(dict['messages'])"
      ],
      "metadata": {
        "id": "b7X5A48iDpgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text', 'from', 'media_type','type','id','date']]\n",
        "df = df.dropna(subset = ['from'])"
      ],
      "metadata": {
        "id": "uV3QjargFM3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['type','from']].groupby(['from']).count().sort_values(['type'], ascending=False)"
      ],
      "metadata": {
        "id": "xNdMXtepEMD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['media_type', 'id']].groupby('media_type', as_index=False).count()"
      ],
      "metadata": {
        "id": "w8SMhsJ0EOqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voice_df = df.loc[df['media_type'] == 'voice_message'][['from', 'id']]\\\n",
        "    .groupby(['from'], as_index=False)\\\n",
        "    .agg('count')\\\n",
        "    .sort_values(['id'], ascending=False)\n",
        "\n",
        "import plotly.express as px\n",
        "fig = px.pie(voice_df, hole=.5, values=voice_df['id'], names=voice_df['from'],\n",
        "             title='Voice messages per person')\n",
        "fig.update_traces(textposition='inside', textinfo='value+label+percent')\n",
        "fig.show()\n",
        "\n",
        "sticker_df = df.loc[df['media_type'] == 'sticker'][['from', 'id']]\\\n",
        "    .groupby(['from'], as_index=False)\\\n",
        "    .agg('count')\\\n",
        "    .sort_values(['id'], ascending=False)\n",
        "\n",
        "import plotly.express as px\n",
        "fig = px.pie(sticker_df, hole=.5, values=sticker_df['id'], names=sticker_df['from'],\n",
        "             title='Stickers sent')\n",
        "fig.update_traces(textposition='inside', textinfo='value+label+percent')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "p9747r_kETpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emojis_in_message(row):\n",
        "    message = row.text\n",
        "    emojis = \"\"\n",
        "    # Telegram may save some messages as json\n",
        "    if message is None or type(message) != str:\n",
        "        return None\n",
        "    return emojis.join(char for char in message if char in emoji.EMOJI_DATA)\n",
        "\n",
        "def get_words_count(row):\n",
        "    message = row.text\n",
        "    emojis = \"\"\n",
        "    # Telegram may save some messages as json\n",
        "    if message is None or type(message) != str:\n",
        "        return None\n",
        "    return re.sub(\"[^\\w]\", \" \",  message).split().__len__()\n",
        "\n",
        "df[\"emojis\"] = df[[\"text\"]].apply(get_emojis_in_message, axis=1)\n",
        "df[\"word_count\"] = df[[\"text\"]].apply(get_words_count, axis=1)"
      ],
      "metadata": {
        "id": "wmedHjaIElcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "people = df['from'].unique()\n",
        "\n",
        "for name in people:\n",
        "    user_df = df[df[\"from\"] == name]\n",
        "    words_per_message = numpy.sum(user_df['word_count'])\n",
        "    print('stats for ', name)\n",
        "    print(name,' sent  ', int(words_per_message), ' words, average ', words_per_message/user_df.shape[0], ' per message')"
      ],
      "metadata": {
        "id": "ZQz8orUVFQTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_emojis_list = list(df.emojis)\n",
        "\n",
        "emoji_dict = {}\n",
        "for i in total_emojis_list:\n",
        "  emoji_dict[i] = emoji_dict.get(i, 0) + 1\n",
        "\n",
        "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
        "emoji_df.replace(to_replace='None', value=numpy.nan).dropna()\n",
        "emoji_df.replace(to_replace=0, value=numpy.nan).dropna()\n",
        "\n",
        "import plotly.express as px\n",
        "fig = px.pie(emoji_df.loc[2:].head(60), hole=.5, values='count', names='emoji',\n",
        "             title='Emoji Distribution')\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "DwcHkq17FSTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = df.text.dropna()\n",
        "text = \" \".join(review for review in df.text.dropna() if review is not None and type(review) == str)\n",
        "print (\"There are {} words in all the messages.\".format(len(text)))\n",
        "\n",
        "stopwords = set(STOPWORDS)\n",
        "stopwords.update([\"Я\",\"Ну\",\"и\",\"это\",\"не\",\"мне\",\"но\",\"А\",\"ты\",\"как\",\"так\",\"что\",\"меня\",\"то\",\"нет\",\"на\",\"в\",\"там\",\"у\",\"с\",\"Да\"])\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "# Display the generated image:\n",
        "pyplot.figure( figsize=(10,5))\n",
        "pyplot.imshow(wordcloud, interpolation='bilinear')\n",
        "pyplot.axis(\"off\")\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "cfPWUkCRFiFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"datetime\"] = pd.to_datetime(df['date'])\n",
        "df.index = df['datetime']\n",
        "date_df = df.resample(\"D\").sum()\n",
        "date_df.reset_index(inplace=True)\n",
        "fig = px.line(date_df, x=\"datetime\", y=\"word_count\", title='Number of words shared as time moves on.')\n",
        "fig.update_xaxes(nticks=30)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7vCkTq0WF57e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"word_count\"].resample(\"D\").sum().sort_values(ascending=False).head(10).plot.barh()\n",
        "\n",
        "df[\"hour\"] = df.datetime.dt.hour\n",
        "df.groupby(\"hour\")[\"word_count\"].sum().head(24).plot.barh()"
      ],
      "metadata": {
        "id": "fQE9LUnqF-aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dayofweek(i):\n",
        "  l = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "  return l[i]\n",
        "\n",
        "day_df=pd.DataFrame(df[\"word_count\"])\n",
        "day_df['day_of_date'] = df['datetime'].dt.weekday\n",
        "day_df['day_of_date'] = day_df[\"day_of_date\"].apply(dayofweek)\n",
        "day_df[\"messagecount\"] = 1\n",
        "day = day_df.groupby(\"day_of_date\").sum()\n",
        "day.reset_index(inplace=True)\n",
        "\n",
        "fig = px.line_polar(day, r='messagecount', theta='day_of_date', line_close=True)\n",
        "fig.update_traces(fill='toself')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AzPrWUoCGB6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}